{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qOSFtdzyhTl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n",
      "Un pequeño erro :P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f07f7e373522>:311: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  f, (ax1) = plt.subplots(1,1, figsize=(x*T/m, y*T/m))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un pequeño erro :P\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import xml.etree.ElementTree as ET\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Concatenate, concatenate, Dropout, LeakyReLU, Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from PIL import Image\n",
    "from os import remove\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# Parameters\n",
    "LABELS           = ('sugarbeet', 'weed')\n",
    "IMAGE_H, IMAGE_W = 512, 512\n",
    "GRID_H,  GRID_W  = 16, 16 # GRID size = IMAGE size / 32\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "SCORE_THRESHOLD  = 0.5 #0.45\n",
    "IOU_THRESHOLD    = 0.45 #0.3\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VAL_BATCH_SIZE   = 10\n",
    "EPOCHS           = 100\n",
    "\n",
    "LAMBDA_NOOBJECT  = 1\n",
    "LAMBDA_OBJECT    = 5\n",
    "LAMBDA_CLASS     = 1\n",
    "LAMBDA_COORD     = 1\n",
    "\n",
    "max_annot        = 0\n",
    "\n",
    "# Train and validation directory\n",
    "Ruta = os.getcwd()+'/'\n",
    "Salida = 'www' #Nombre carpeta de salida\n",
    "Entrada = 'FOLDER' #Nombre carpeta de entrada\n",
    "\n",
    "# Custom Keras layer\n",
    "class SpaceToDepth(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, block_size, **kwargs):\n",
    "        self.block_size = block_size\n",
    "        super(SpaceToDepth, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        batch, height, width, depth = K.int_shape(x)\n",
    "        batch = -1\n",
    "        reduced_height = height // self.block_size\n",
    "        reduced_width = width // self.block_size\n",
    "        y = K.reshape(x, (batch, reduced_height, self.block_size,\n",
    "                             reduced_width, self.block_size, depth))\n",
    "        z = K.permute_dimensions(y, (0, 1, 3, 2, 4, 5))\n",
    "        t = K.reshape(z, (batch, reduced_height, reduced_width, depth * self.block_size **2))\n",
    "        return t\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape =  (input_shape[0], input_shape[1] // self.block_size, input_shape[2] // self.block_size,\n",
    "                  input_shape[3] * self.block_size **2)\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "# Yolo model \n",
    "input_image = tf.keras.layers.Input((IMAGE_H, IMAGE_W, 3), dtype='float32')\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "\n",
    "skip_connection = SpaceToDepth(block_size=2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = Dropout(0.3)(x) # add dropout\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_W, GRID_H, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "model = keras.models.Model(input_image, output)\n",
    "\n",
    "# Test generator pipeline\n",
    "model.load_weights(Ruta+'Ultimo.h5') # best weights, comment to start with YOLO weights\n",
    "\n",
    "#5. Results\n",
    "def display_yolo(file, model, score_threshold, iou_threshold):\n",
    "    '''\n",
    "    Display predictions from YOLO model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - file : string list : list of images path.\n",
    "    - model : YOLO model.\n",
    "    - score_threshold : threshold used for filtering predicted bounding boxes.\n",
    "    - iou_threshold : threshold used for non max suppression.\n",
    "    '''\n",
    "    # load image\n",
    "    #image = cv2.imread(file)\n",
    "\n",
    "    pic = Image.open(file)\n",
    "    # Define tupla con región\n",
    "    caja = (0, 0, 512, 512)\n",
    "\n",
    "    # Obtener de la imagen original la región de la caja\n",
    "    pic = pic.crop(caja)  \n",
    "\n",
    "    image = np.array(pic.getdata()).reshape(pic.size[0], pic.size[1], 3)\n",
    "\n",
    "# change size    \n",
    "#####    \n",
    "    X_Y = np.sum(image[:,:,:],axis=2)\n",
    "    X = np.where(np.mean(X_Y,axis=0)==0)[0]\n",
    "    Y = np.where(np.mean(X_Y,axis=1)==0)[0]\n",
    "    if len(X)>0:\n",
    "        x = X[0];\n",
    "    else:\n",
    "        x = IMAGE_W\n",
    "    \n",
    "    if len(Y)>0:\n",
    "        y = Y[0];\n",
    "    else:\n",
    "        y = IMAGE_H\n",
    "        \n",
    "    Recorte = image[:y,:x,:]\n",
    "    \n",
    "#####\n",
    "\n",
    "    input_image = image / 255.\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "    \n",
    "    # prediction\n",
    "    y_pred = model.predict_on_batch(input_image)\n",
    "\n",
    "\n",
    "    # post prediction process\n",
    "    # grid coords tensor\n",
    "    coord_x = tf.cast(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)), tf.float32)\n",
    "    coord_y = tf.transpose(coord_x, (0,2,1,3,4))\n",
    "    coords = tf.tile(tf.concat([coord_x,coord_y], -1), [TRAIN_BATCH_SIZE, 1, 1, 5, 1])\n",
    "    dims = K.cast_to_floatx(K.int_shape(y_pred)[1:3])\n",
    "    dims = K.reshape(dims,(1,1,1,1,2))\n",
    "    # anchors tensor\n",
    "    anchors = np.array(ANCHORS)\n",
    "    anchors = anchors.reshape(len(anchors) // 2, 2)\n",
    "    # pred_xy and pred_wh shape (m, GRID_W, GRID_H, Anchors, 2)\n",
    "    pred_xy = K.sigmoid(y_pred[:,:,:,:,0:2])\n",
    "    pred_xy = (pred_xy + coords)\n",
    "    pred_xy = pred_xy / dims\n",
    "    pred_wh = K.exp(y_pred[:,:,:,:,2:4])\n",
    "    pred_wh = (pred_wh * anchors)\n",
    "    pred_wh = pred_wh / dims\n",
    "    # pred_confidence\n",
    "    box_conf = K.sigmoid(y_pred[:,:,:,:,4:5])  \n",
    "    # pred_class\n",
    "    box_class_prob = K.softmax(y_pred[:,:,:,:,5:])\n",
    "\n",
    "    # Reshape\n",
    "    pred_xy = pred_xy[0,...]\n",
    "    pred_wh = pred_wh[0,...]\n",
    "    box_conf = box_conf[0,...]\n",
    "    box_class_prob = box_class_prob[0,...]\n",
    "\n",
    "    # Convert box coords from x,y,w,h to x1,y1,x2,y2\n",
    "    box_xy1 = pred_xy - 0.5 * pred_wh\n",
    "    box_xy2 = pred_xy + 0.5 * pred_wh\n",
    "    boxes = K.concatenate((box_xy1, box_xy2), axis=-1)\n",
    "\n",
    "    # Filter boxes\n",
    "    box_scores = box_conf * box_class_prob\n",
    "    box_classes = K.argmax(box_scores, axis=-1) # best score index\n",
    "    box_class_scores = K.max(box_scores, axis=-1) # best score\n",
    "    prediction_mask = box_class_scores >= score_threshold\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "\n",
    "    # Scale box to image shape\n",
    "    boxes = boxes * IMAGE_H\n",
    "\n",
    "    # Non Max Supression\n",
    "    selected_idx = tf.image.non_max_suppression(boxes, scores, 50, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, selected_idx)\n",
    "    scores = K.gather(scores, selected_idx)\n",
    "    classes = K.gather(classes, selected_idx)\n",
    "    \n",
    "    ####\n",
    "    T = 10;\n",
    "    m = np.max([x,y])\n",
    "    ####\n",
    "       \n",
    "    f, (ax1) = plt.subplots(1,1, figsize=(x*T/m, y*T/m))\n",
    "    ax1.imshow(Recorte)\n",
    "    count_detected = boxes.shape[0]\n",
    "#   ax1.set_title('Detected objects count : {}'.format(count_detected))\n",
    "    extent = ax1.get_window_extent().transformed(f.dpi_scale_trans.inverted())\n",
    "    \n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    for i in range(count_detected):\n",
    "        box = boxes[i,...]\n",
    "        x = box[0]\n",
    "        y = box[1]\n",
    "        w = box[2] - box[0]\n",
    "        h = box[3] - box[1]\n",
    "        classe = classes[i].numpy()\n",
    "        if classe == 0:\n",
    "            color = (0, 1, 0)\n",
    "        else:\n",
    "            color = (1, 0, 0)\n",
    "        rect = patches.Rectangle((x.numpy(), y.numpy()), w.numpy(), h.numpy(), linewidth = 3, edgecolor=color,facecolor='none')\n",
    "        ax1.add_patch(rect)\n",
    "         \n",
    "    return f, extent\n",
    "\n",
    "\n",
    "# TEST \n",
    "\n",
    "shutil.copy(Ruta+'rstudio.png', Ruta+Salida+'/rstudio.png')\n",
    "\n",
    "while 1:\n",
    "    x_files =  glob.glob(Ruta+Entrada+'/*.png')\n",
    "    try:\n",
    "        for file in x_files:\n",
    "            ax,extent = display_yolo(file, model, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "            ax.savefig(Ruta+Salida+'/rstudio.png', facecolor='black', bbox_inches=extent)\n",
    "            remove(file)\n",
    "            time.sleep(1)\n",
    "    except:\n",
    "        print(\"Un pequeño erro :P\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Archivos = glob.glob('/home/dpc/Manzanas/apple_dataset/validation/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Archivos: \n",
    "#    imagen = Image.open(i)\n",
    "\n",
    "\n",
    "# Define tupla con región\n",
    "#    caja = (0, 0, 512, 512)\n",
    "\n",
    "# Obtener de la imagen original la región de la caja\n",
    "#    region = imagen.crop(caja)  \n",
    "\n",
    "#    region.show()  # Mostrar imagen de la region\n",
    "#    region.size   # Mostrar tamaño de imagen final 512*512\n",
    "#    region.save(i.split('.')[0]+'.png')\n",
    "#    remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño = 0;\n",
    "#for i in Archivos: \n",
    "#    imagen = Image.open(i)\n",
    "#    if np.max(imagen.size) > Tamaño:\n",
    "#        Tamaño =  np.max(imagen.size);\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista = glob.glob('/home/dpc/Manzanas/apple_dataset/val/annotation/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in Lista: \n",
    "#    doc = etree.parse(i)\n",
    "#    root = doc.getroot()\n",
    "#    Nombres = []\n",
    "#    for child in root:\n",
    "#        Nombres.append(child.tag)\n",
    "\n",
    "#    Posicion = np.where(np.array(Nombres) == 'filename')[0][0];    \n",
    "#    Nombre = root[Posicion].text \n",
    "#    root[Posicion].text = Nombre.split('.')[0]+'.png'\n",
    "#    doc.write(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Y2_listo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
